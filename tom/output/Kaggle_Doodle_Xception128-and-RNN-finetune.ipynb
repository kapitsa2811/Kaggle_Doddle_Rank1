{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom/anaconda2/envs/python36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import os\n",
    "import ast\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.metrics import categorical_accuracy, top_k_categorical_accuracy, categorical_crossentropy\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, LearningRateScheduler\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications import MobileNet\n",
    "from keras.applications import ResNet50\n",
    "from keras.applications import InceptionResNetV2\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.xception import preprocess_input\n",
    "# from keras.applications.inception_resnet_v2 import preprocess_input\n",
    "# from keras.applications.resnet50 import preprocess_input\n",
    "# from keras.applications.mobilenet import preprocess_input\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras import Model\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.models import load_model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers import GlobalAveragePooling2D, Reshape, Dense, multiply, Permute, Input\n",
    "from keras.layers import UpSampling2D, Conv2D, Conv2DTranspose, Concatenate, MaxPooling2D\n",
    "from keras.layers import concatenate, Dropout, BatchNormalization, Lambda, Flatten, Activation\n",
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import BatchNormalization, Conv1D, LSTM, Dense, Dropout, Bidirectional\n",
    "#if len(get_available_gpus())>0:\n",
    "    # https://twitter.com/fchollet/status/918170264608817152?lang=en\n",
    "from keras.layers import CuDNNLSTM as LSTM # this one is about 3x faster on GPU instances\n",
    "from keras import backend as K\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "from alt_model_checkpoint import AltModelCheckpoint\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def step_decay_exp(epoch):\n",
    "    initial_lrate = 0.01\n",
    "    drop = 0.5 # drop by how much? 0.5 = half each time\n",
    "    epochs_drop = 10.0 # drop how many x epochs\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "def cse_block(input, prefix, ratio=16):\n",
    "    ''' Create a squeeze-excite block\n",
    "    Args:\n",
    "        input: input tensor\n",
    "        filters: number of output filters\n",
    "        k: width factor\n",
    "    Returns: a keras tensor\n",
    "    '''\n",
    "    init = input\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "    filters = init._keras_shape[channel_axis]\n",
    "    se_shape = (1, 1, filters)\n",
    "\n",
    "    se = GlobalAveragePooling2D(name = prefix + \"_cse_gap1\")(init)\n",
    "    se = Reshape(se_shape, name = prefix + \"_cse_reshape1\")(se)\n",
    "    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False,\n",
    "              name = prefix + \"_cse_fc1\")(se)\n",
    "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False,\n",
    "              name = prefix + \"_cse_fc2\")(se)\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        se = Permute((3, 1, 2))(se)\n",
    "\n",
    "    x = multiply([init, se], name = prefix + \"_cse_mul1\")\n",
    "    return x\n",
    "\n",
    "def sse_block(input, prefix):\n",
    "    init = input\n",
    "    conv = Conv2D(1, (1,1), padding = 'same', kernel_initializer = 'he_normal',\n",
    "                  activation = 'sigmoid', strides = (1,1), name = prefix + \"_sse_conv\")(input)\n",
    "    conv = Multiply(name = prefix + \"_sse_mul1\")([input, conv])\n",
    "    return conv\n",
    "\n",
    "def csse_block(x, prefix):\n",
    "    cse = cse_block(x, prefix)\n",
    "    sse = sse_block(x, prefix)\n",
    "    out = Add(name = prefix + \"_csse_mul\")([cse, sse])\n",
    "    return out\n",
    "\n",
    "\n",
    "def apk(actual, predicted, k=3):\n",
    "    \"\"\"\n",
    "    Source: https://github.com/benhamner/Metrics/blob/master/Python/ml_metrics/average_precision.py\n",
    "    \"\"\"\n",
    "    if len(predicted) > k:\n",
    "        predicted = predicted[:k]\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "    for i, p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i + 1.0)\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=3):\n",
    "    \"\"\"\n",
    "    Source: https://github.com/benhamner/Metrics/blob/master/Python/ml_metrics/average_precision.py\n",
    "    \"\"\"\n",
    "    return np.mean([apk(a, p, k) for a, p in zip(actual, predicted)])\n",
    "\n",
    "def preds2catids(predictions):\n",
    "    return pd.DataFrame(np.argsort(-predictions, axis=1)[:, :3], columns=['a', 'b', 'c'])\n",
    "\n",
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "\n",
    "\n",
    "def f2cat(filename: str) -> str:\n",
    "    return filename.split('.')[0]\n",
    "\n",
    "def list_all_categories():\n",
    "    files = os.listdir(os.path.join(INPUT_DIR, 'train_simplified'))\n",
    "    return sorted([f2cat(f) for f in files], key=str.lower)\n",
    "\n",
    "\n",
    "def _stack_it(raw_strokes):\n",
    "    \"\"\"preprocess the string and make \n",
    "    a standard Nx3 stroke vector\"\"\"\n",
    " #   stroke_vec = literal_eval(raw_strokes) # string->list\n",
    "    # unwrap the list\n",
    "    stroke_vec = ast.literal_eval(raw_strokes)\n",
    "    in_strokes = [(xi,yi,zi,i)  \n",
    "     for i,(x,y,z) in enumerate(stroke_vec) \n",
    "     for xi,yi,zi in zip(x,y,z)]\n",
    "    c_strokes = np.stack(in_strokes)\n",
    "    # replace stroke id with 1 for continue, 2 for new\n",
    "#    c_strokes[:,3] = [1]+np.diff(c_strokes[:,3]).tolist()\n",
    "#    c_strokes[:,3] += 1 # since 0 is no stroke\n",
    "    # pad the strokes with zeros\n",
    "    return pad_sequences(c_strokes.swapaxes(0, 1), \n",
    "                         maxlen=STROKE_COUNT, \n",
    "                         padding='post').swapaxes(0, 1)\n",
    "\n",
    "### Image Generator\n",
    "def draw_cv2(raw_strokes, size=256, lw=6, time_color=True):\n",
    "    img = np.zeros((BASE_SIZE, BASE_SIZE), np.uint8)\n",
    "    for t, stroke in enumerate(raw_strokes):\n",
    "        for i in range(len(stroke[0]) - 1):\n",
    "            # can try to do exponential smoothing / decay\n",
    "            # how about embedding different elements/colours to different channels\n",
    "            # one channel has raw 0/255\n",
    "            # one channel has decay 0->255\n",
    "            # one channel has decay 0->255 but with different line width\n",
    "            color = 255 - min(t, 15) * 13 if time_color else 255\n",
    "            _ = cv2.line(img, (stroke[0][i], stroke[1][i]),\n",
    "                         (stroke[0][i + 1], stroke[1][i + 1]), color, lw)\n",
    "    if size != BASE_SIZE:\n",
    "        return cv2.resize(img, (size, size))\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "def image_generator_xd(size, batchsize, ks, lw=6, time_color=True):\n",
    "    while True:\n",
    "        for k in np.random.permutation(ks):\n",
    "#             print('Chosen {}'.format(k))\n",
    "            filename = os.path.join(DP_DIR, 'train_k{}.csv.gz'.format(k))\n",
    "            for df in pd.read_csv(filename, chunksize=batchsize):\n",
    "                df['drawing'] = df['time'].apply(ast.literal_eval)\n",
    "                x = np.zeros((len(df), size, size, 3))\n",
    "                for i, raw_strokes in enumerate(df.drawing.values):\n",
    "                    x[i, :, :, 0] = draw_cv2(raw_strokes, size=size, lw=lw,\n",
    "                                             time_color=time_color)\n",
    "                for i, raw_strokes in enumerate(df.drawing.values):\n",
    "                    x[i, :, :, 1] = draw_cv2(raw_strokes, size=size, lw=lw,\n",
    "                                             time_color=False)\n",
    "                for i, raw_strokes in enumerate(df.drawing.values):\n",
    "                    x[i, :, :, 2] = draw_cv2(raw_strokes, size=size, lw=4,\n",
    "                                             time_color=True)\n",
    "#                 x = np.repeat(x, 3, axis = 3)\n",
    "                x = preprocess_input(x).astype(np.float32)\n",
    "                y = keras.utils.to_categorical(df.y, num_classes=NCATS)\n",
    "                df['time'] = df['time'].map(_stack_it)\n",
    "                x2 = np.stack(df['time'], 0)\n",
    "                yield [x, x2], y\n",
    "\n",
    "def df_to_image_array_xd(df, size, lw=6, time_color=True):\n",
    "    df['drawing'] = df['time'].apply(ast.literal_eval)\n",
    "    x = np.zeros((len(df), size, size, 3))\n",
    "    for i, raw_strokes in enumerate(df.drawing.values):\n",
    "        x[i, :, :, 0] = draw_cv2(raw_strokes, size=size, lw=lw, time_color=time_color)\n",
    "    for i, raw_strokes in enumerate(df.drawing.values):\n",
    "        x[i, :, :, 1] = draw_cv2(raw_strokes, size=size, lw=lw, time_color=False)\n",
    "    for i, raw_strokes in enumerate(df.drawing.values):\n",
    "        x[i, :, :, 2] = draw_cv2(raw_strokes, size=size, lw=4, time_color=True)\n",
    "    x = preprocess_input(x).astype(np.float32)\n",
    "    df['time'] = df['time'].map(_stack_it)\n",
    "    x2 = np.stack(df['time'], 0)\n",
    "    return  [x, x2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "DP_DIR = './input/train_time_100k/'\n",
    "INPUT_DIR = './input/'\n",
    "STROKE_COUNT = 100\n",
    "BASE_SIZE = 256\n",
    "NCSVS = 20\n",
    "NCATS = 340\n",
    "np.random.seed(seed=123)\n",
    "tf.set_random_seed(seed=123)\n",
    "size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 63, 63, 32)   864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 63, 63, 32)   128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 63, 63, 32)   0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 61, 61, 64)   18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 61, 61, 64)   256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 61, 61, 64)   0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 61, 61, 128)  8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 61, 61, 128)  512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 61, 61, 128)  0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 61, 61, 128)  17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 61, 61, 128)  512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 31, 31, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 31, 31, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 31, 31, 128)  512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 31, 31, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 31, 31, 128)  0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 31, 31, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 31, 31, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 31, 31, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 31, 31, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 31, 31, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 256)  32768       add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 16, 16, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 256)  1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 16, 16, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 16, 16, 256)  0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 16, 16, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 16, 16, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 8, 8, 728)    186368      add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 8, 8, 728)    0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 8, 8, 728)    2912        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 8, 8, 728)    0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 8, 8, 728)    0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 8, 8, 728)    0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 8, 8, 728)    0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 8, 8, 728)    0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 8, 8, 728)    0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 8, 8, 728)    0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 8, 8, 728)    0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 8, 8, 728)    0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 8, 8, 728)    0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 8, 8, 728)    0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 8, 8, 728)    0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 8, 8, 728)    0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 8, 8, 728)    0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 8, 8, 728)    0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 8, 8, 728)    0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 8, 8, 728)    0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 8, 8, 728)    0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 8, 8, 728)    0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 8, 8, 728)    0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 8, 8, 728)    0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 8, 8, 728)    0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 8, 8, 728)    0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 8, 8, 728)    0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 8, 8, 728)    0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 8, 8, 728)    0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 8, 8, 728)    0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 8, 8, 728)    0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 8, 8, 728)    0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 8, 8, 728)    0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 8, 8, 728)    0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 8, 8, 1024)   752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 8, 8, 1024)   4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 4, 4, 1024)   745472      add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 4, 4, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 4, 4, 1024)   4096        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 4, 4, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 4, 4, 1536)   1582080     add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 4, 4, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 4, 4, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 4, 4, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 4, 4, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 4, 4, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool_n (GlobalAveragePoolin (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 2048)         4196352     avg_pool_n[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 2048)         0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 340)          696660      dropout_8[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 25,754,492\n",
      "Trainable params: 0\n",
      "Non-trainable params: 25,754,492\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model_cnn=None\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    # create the base pre-trained model\n",
    "    base_model_cnn  = Xception(input_shape = (128, 128, 3), include_top = False, weights = 'imagenet')\n",
    "\n",
    "   \n",
    "    # first: train only the top layers (which were randomly initialized)\n",
    "    # i.e. freeze all convolutional InceptionV3 layers\n",
    "   \n",
    "\n",
    "\n",
    "    # add a global spatial average pooling layer\n",
    "    x = base_model_cnn.output\n",
    "    x = GlobalAveragePooling2D(name='avg_pool_n')(x)\n",
    "    x=Dense(2048, activation = 'relu')(x) \n",
    "    # let's add a fully-connected layer\n",
    "    x = Dropout(0.2)(x)\n",
    "    predictions = Dense(340, activation='softmax', name='predictions')(x)\n",
    "    base_model_cnn  = Model(inputs=base_model_cnn.input,  outputs=predictions)\n",
    "  #  base_model_cnn.load_weights('keras_models/xception_model_tom_095433.h5')\n",
    "\n",
    "    for layer in base_model_cnn.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    base_model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_10 (Batc (None, None, 4)           16        \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, None, 256)         5376      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, None, 256)         0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, None, 1024)        3153920   \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, None, 1024)        0         \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 1024)              6299648   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2048)              2099200   \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 340)               696660    \n",
      "=================================================================\n",
      "Total params: 12,254,820\n",
      "Trainable params: 0\n",
      "Non-trainable params: 12,254,820\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model_rnn=None\n",
    "with tf.device(\"cpu:0\"):\n",
    "    \n",
    "    base_model_rnn = Sequential()\n",
    "    base_model_rnn.add(BatchNormalization(input_shape = (None,)+(4,)))\n",
    "    # filter count and length are taken from the script https://github.com/tensorflow/models/blob/master/tutorials/rnn/quickdraw/train_model.py\n",
    "    base_model_rnn.add(Conv1D(256, (5,), activation = 'relu'))\n",
    "    base_model_rnn.add(Dropout(0.2))\n",
    "    #base_rnn_model.add(Conv1D(512, (5,), activation = 'relu'))\n",
    "    #base_rnn_model.add(Dropout(0.2))\n",
    "    #base_rnn_model.add(Conv1D(512, (3,), activation = 'relu'))\n",
    "    #base_rnn_model.add(Dropout(0.2))\n",
    "    #base_rnn_model.add(Bidirectional(LSTM(256, return_sequences = True)))\n",
    "    #base_rnn_model.add(Dropout(0.2))\n",
    "    base_model_rnn.add(Bidirectional(LSTM(512, return_sequences = True)))\n",
    "    base_model_rnn.add(Dropout(0.2))\n",
    "    base_model_rnn.add(Bidirectional(LSTM(512, return_sequences = False)))\n",
    "    base_model_rnn.add(Dense(2048, activation = 'relu'))\n",
    "    base_model_rnn.add(Dropout(0.2))\n",
    "    base_model_rnn.add(Dense(NCATS, activation = 'softmax'))\n",
    "   # base_model_rnn.load_weights('keras_models/stroke_lstm_bidirectional_relu_weights_0926.best.hdf5')\n",
    "    for layer in base_model_rnn.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    base_model_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 63, 63, 32)   864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 63, 63, 32)   128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 63, 63, 32)   0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 61, 61, 64)   18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 61, 61, 64)   256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 61, 61, 64)   0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 61, 61, 128)  8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 61, 61, 128)  512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 61, 61, 128)  0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 61, 61, 128)  17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 61, 61, 128)  512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 31, 31, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 31, 31, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 31, 31, 128)  512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 31, 31, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 31, 31, 128)  0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 31, 31, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 31, 31, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 31, 31, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 31, 31, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 31, 31, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 256)  32768       add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 16, 16, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 256)  1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 16, 16, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 16, 16, 256)  0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 16, 16, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 16, 16, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 8, 8, 728)    186368      add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 8, 8, 728)    0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 8, 8, 728)    2912        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 8, 8, 728)    0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 8, 8, 728)    0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 8, 8, 728)    0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 8, 8, 728)    0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 8, 8, 728)    0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 8, 8, 728)    0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 8, 8, 728)    0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 8, 8, 728)    0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 8, 8, 728)    0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 8, 8, 728)    0           add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 8, 8, 728)    0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 8, 8, 728)    0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 8, 8, 728)    0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 8, 8, 728)    0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 8, 8, 728)    0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 8, 8, 728)    0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 8, 8, 728)    0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 8, 8, 728)    0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 8, 8, 728)    0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 8, 8, 728)    0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 8, 8, 728)    0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 8, 8, 728)    0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 8, 8, 728)    0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 8, 8, 728)    0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 8, 8, 728)    0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 8, 8, 728)    0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 8, 8, 728)    0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 8, 8, 728)    0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 8, 8, 728)    0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 8, 8, 728)    0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 8, 8, 728)    0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 8, 8, 1024)   752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 8, 8, 1024)   4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 4, 4, 1024)   745472      add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 4, 4, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 4, 4, 1024)   4096        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 4, 4, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 4, 4, 1536)   1582080     add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10_input (I (None, None, 4)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 4, 4, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, None, 4)      16          batch_normalization_10_input[0][0\n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 4, 4, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, None, 256)    5376        batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 4, 4, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, None, 256)    0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 4, 4, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, None, 1024)   3153920     dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 4, 4, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, None, 1024)   0           bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool_n (GlobalAveragePoolin (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 1024)         6299648     dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 2048)         4196352     avg_pool_n[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 2048)         2099200     bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 4096)         0           dense_7[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 4096)         0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 340)          1392980     dropout_12[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 38,008,972\n",
      "Trainable params: 37,954,436\n",
      "Non-trainable params: 54,536\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"cpu:0\"):\n",
    "    cnn_output=base_model_cnn.layers[-3].output\n",
    "    rnn_output=base_model_rnn.layers[-3].output\n",
    "    \n",
    "    cnn_input=base_model_cnn.input\n",
    "    rnn_input=base_model_rnn.input\n",
    "    \n",
    "    x = concatenate([cnn_output, rnn_output])\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(NCATS, activation='softmax')(x)\n",
    "    base_model = Model([cnn_input, rnn_input], x)\n",
    "    base_model.load_weights('./keras_models/xception_rnn_model_tom_last_0954.h5')\n",
    "    \n",
    "    for layer in base_model_cnn.layers:\n",
    "        layer.trainable = True\n",
    "    for layer in base_model_rnn.layers:\n",
    "        layer.trainable = True\n",
    "    base_model.summary()\n",
    "gpu_model = multi_gpu_model(base_model, gpus=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "4394/4394 [==============================] - 5703s 1s/step - loss: 0.5645 - categorical_crossentropy: 0.5645 - categorical_accuracy: 0.8485 - top_3_accuracy: 0.9501 - val_loss: 0.5324 - val_categorical_crossentropy: 0.5324 - val_categorical_accuracy: 0.8566 - val_top_3_accuracy: 0.9539\n",
      "\n",
      "Epoch 00001: val_top_3_accuracy improved from -inf to 0.95392, saving model to xception_rnn_model_tom.h5\n",
      "Epoch 2/8\n",
      "4394/4394 [==============================] - 5616s 1s/step - loss: 0.5575 - categorical_crossentropy: 0.5575 - categorical_accuracy: 0.8505 - top_3_accuracy: 0.9508 - val_loss: 0.5369 - val_categorical_crossentropy: 0.5369 - val_categorical_accuracy: 0.8561 - val_top_3_accuracy: 0.9535\n",
      "\n",
      "Epoch 00002: val_top_3_accuracy did not improve from 0.95392\n",
      "Epoch 3/8\n",
      "4394/4394 [==============================] - 5646s 1s/step - loss: 0.5545 - categorical_crossentropy: 0.5545 - categorical_accuracy: 0.8513 - top_3_accuracy: 0.9513 - val_loss: 0.5411 - val_categorical_crossentropy: 0.5411 - val_categorical_accuracy: 0.8540 - val_top_3_accuracy: 0.9526\n",
      "\n",
      "Epoch 00003: val_top_3_accuracy did not improve from 0.95392\n",
      "Epoch 4/8\n",
      "4394/4394 [==============================] - 5613s 1s/step - loss: 0.5714 - categorical_crossentropy: 0.5714 - categorical_accuracy: 0.8476 - top_3_accuracy: 0.9492 - val_loss: 0.5374 - val_categorical_crossentropy: 0.5374 - val_categorical_accuracy: 0.8546 - val_top_3_accuracy: 0.9532\n",
      "\n",
      "Epoch 00004: val_top_3_accuracy did not improve from 0.95392\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00033000001567415896.\n",
      "Epoch 5/8\n",
      "4394/4394 [==============================] - 5611s 1s/step - loss: 0.5470 - categorical_crossentropy: 0.5470 - categorical_accuracy: 0.8538 - top_3_accuracy: 0.9520 - val_loss: 0.5226 - val_categorical_crossentropy: 0.5226 - val_categorical_accuracy: 0.8600 - val_top_3_accuracy: 0.9548\n",
      "\n",
      "Epoch 00005: val_top_3_accuracy improved from 0.95392 to 0.95482, saving model to xception_rnn_model_tom.h5\n",
      "Epoch 6/8\n",
      "4394/4394 [==============================] - 5637s 1s/step - loss: 0.5521 - categorical_crossentropy: 0.5521 - categorical_accuracy: 0.8527 - top_3_accuracy: 0.9512 - val_loss: 0.5184 - val_categorical_crossentropy: 0.5184 - val_categorical_accuracy: 0.8605 - val_top_3_accuracy: 0.9548\n",
      "\n",
      "Epoch 00006: val_top_3_accuracy did not improve from 0.95482\n",
      "Epoch 7/8\n",
      "4394/4394 [==============================] - 5630s 1s/step - loss: 0.5432 - categorical_crossentropy: 0.5432 - categorical_accuracy: 0.8546 - top_3_accuracy: 0.9523 - val_loss: 0.5108 - val_categorical_crossentropy: 0.5108 - val_categorical_accuracy: 0.8631 - val_top_3_accuracy: 0.9559\n",
      "\n",
      "Epoch 00007: val_top_3_accuracy improved from 0.95482 to 0.95590, saving model to xception_rnn_model_tom.h5\n",
      "Epoch 8/8\n",
      "4394/4394 [==============================] - 5627s 1s/step - loss: 0.5342 - categorical_crossentropy: 0.5342 - categorical_accuracy: 0.8569 - top_3_accuracy: 0.9533 - val_loss: 0.5149 - val_categorical_crossentropy: 0.5149 - val_categorical_accuracy: 0.8612 - val_top_3_accuracy: 0.9549\n",
      "\n",
      "Epoch 00008: val_top_3_accuracy did not improve from 0.95590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fac523e80b8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Xception\n",
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "EPOCHS = 8\n",
    "TOTAL_TRAIN = 2250000\n",
    "BATCH_SIZE = 128 * 4\n",
    "STEPS = TOTAL_TRAIN // BATCH_SIZE\n",
    "\n",
    "train_datagen = image_generator_xd(size=size, batchsize=BATCH_SIZE, ks=range(NCSVS - 1))\n",
    "valid_datagen = image_generator_xd(size=size, batchsize=BATCH_SIZE, ks=NCSVS - 1)\n",
    "\n",
    "def step_decay_exp(epoch):\n",
    "    initial_lrate = 0.001\n",
    "    drop = 0.5 # drop by how much? 0.5 = half each time\n",
    "    epochs_drop = 7.0 # drop how many x epochs\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return max(1e-6, lrate)\n",
    "\n",
    "callbacks = [\n",
    "    AltModelCheckpoint('xception_rnn_model_tom.h5',base_model, monitor = 'val_top_3_accuracy', mode = 'max', save_best_only = True, verbose = 1),\n",
    "    AltModelCheckpoint('xception_rnn_model_tom_last.h5', base_model,monitor = 'val_top_3_accuracy', mode = 'max', save_best_only = False, verbose = 0),\n",
    "    ReduceLROnPlateau(monitor='val_top_3_accuracy', factor=0.66, patience=3,\n",
    "                      min_lr = 0.000001, \n",
    "                      mode='max', \n",
    "                      cooldown=3, verbose=1),\n",
    "#     LearningRateScheduler(step_decay_exp),\n",
    "    CSVLogger('xception_log.csv', append=True, separator=';')\n",
    "]\n",
    "\n",
    "# sgdOptimiser = SGD(lr = 0.001, momentum=0.9, decay = 0.0001,  nesterov=True)\n",
    "\n",
    "gpu_model.compile(optimizer=Adam(lr=0.0005), loss='categorical_crossentropy',\n",
    "              metrics=[categorical_crossentropy, categorical_accuracy, top_3_accuracy])\n",
    "\n",
    "gpu_model.fit_generator(\n",
    "    train_datagen, steps_per_epoch=STEPS, epochs=EPOCHS, verbose=1,\n",
    "    validation_data = valid_datagen, validation_steps = STEPS // 13, # can try STEPS // 6 or 7 for more consistent validation\n",
    "    callbacks = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = multi_gpu_model(base_model, gpus=4)       \n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.00005), \n",
    "              metrics=[top_k_categorical_accuracy, 'accuracy'])\n",
    "\n",
    "\n",
    "gpu_model.fit_generator(\n",
    "    train_datagen, steps_per_epoch=STEPS, epochs=10, verbose=1,\n",
    "    validation_data = valid_datagen, validation_steps = STEPS // 13, # can try STEPS // 6 or 7 for more consistent validation\n",
    "    callbacks = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom/anaconda2/envs/python36/lib/python3.6/site-packages/ipykernel_launcher.py:201: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/tom/anaconda2/envs/python36/lib/python3.6/site-packages/ipykernel_launcher.py:210: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 38s 1ms/step\n",
      "Pred shape: (30000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 24s 784us/step\n",
      "Pred shape: (60000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 847us/step\n",
      "Pred shape: (90000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 849us/step\n",
      "Pred shape: (120000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 24s 793us/step\n",
      "Pred shape: (150000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 843us/step\n",
      "Pred shape: (180000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 835us/step\n",
      "Pred shape: (210000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 836us/step\n",
      "Pred shape: (240000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 832us/step\n",
      "Pred shape: (270000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 822us/step\n",
      "Pred shape: (300000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 26s 865us/step\n",
      "Pred shape: (330000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 838us/step\n",
      "Pred shape: (360000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 831us/step\n",
      "Pred shape: (390000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 822us/step\n",
      "Pred shape: (420000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 24s 812us/step\n",
      "Pred shape: (450000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 819us/step\n",
      "Pred shape: (480000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 23s 778us/step\n",
      "Pred shape: (510000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 24s 804us/step\n",
      "Pred shape: (540000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 24s 810us/step\n",
      "Pred shape: (570000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 26s 852us/step\n",
      "Pred shape: (600000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 838us/step\n",
      "Pred shape: (630000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 24s 812us/step\n",
      "Pred shape: (660000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 827us/step\n",
      "Pred shape: (690000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 831us/step\n",
      "Pred shape: (720000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 24s 792us/step\n",
      "Pred shape: (750000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 849us/step\n",
      "Pred shape: (780000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 831us/step\n",
      "Pred shape: (810000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 837us/step\n",
      "Pred shape: (840000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 26s 868us/step\n",
      "Pred shape: (870000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 831us/step\n",
      "Pred shape: (900000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 26s 851us/step\n",
      "Pred shape: (930000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 848us/step\n",
      "Pred shape: (960000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 835us/step\n",
      "Pred shape: (990000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 849us/step\n",
      "Pred shape: (1020000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 843us/step\n",
      "Pred shape: (1050000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 847us/step\n",
      "Pred shape: (1080000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 833us/step\n",
      "Pred shape: (1110000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 841us/step\n",
      "Pred shape: (1140000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 817us/step\n",
      "Pred shape: (1170000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 26s 857us/step\n",
      "Pred shape: (1200000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 26s 857us/step\n",
      "Pred shape: (1230000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 26s 856us/step\n",
      "Pred shape: (1260000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 26s 869us/step\n",
      "Pred shape: (1290000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 26s 853us/step\n",
      "Pred shape: (1320000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 825us/step\n",
      "Pred shape: (1350000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 26s 855us/step\n",
      "Pred shape: (1380000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 26s 857us/step\n",
      "Pred shape: (1410000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 838us/step\n",
      "Pred shape: (1440000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 825us/step\n",
      "Pred shape: (1470000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 844us/step\n",
      "Pred shape: (1500000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 26s 858us/step\n",
      "Pred shape: (1530000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 840us/step\n",
      "Pred shape: (1560000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 26s 858us/step\n",
      "Pred shape: (1590000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 26s 856us/step\n",
      "Pred shape: (1620000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 849us/step\n",
      "Pred shape: (1650000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 26s 850us/step\n",
      "Pred shape: (1680000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 843us/step\n",
      "Pred shape: (1710000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 26s 853us/step\n",
      "Pred shape: (1740000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 832us/step\n",
      "Pred shape: (1770000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 841us/step\n",
      "Pred shape: (1800000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 841us/step\n",
      "Pred shape: (1830000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 26s 852us/step\n",
      "Pred shape: (1860000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 26s 856us/step\n",
      "Pred shape: (1890000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 843us/step\n",
      "Pred shape: (1920000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 26s 857us/step\n",
      "Pred shape: (1950000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 846us/step\n",
      "Pred shape: (1980000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 835us/step\n",
      "Pred shape: (2010000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 844us/step\n",
      "Pred shape: (2040000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 26s 864us/step\n",
      "Pred shape: (2070000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 840us/step\n",
      "Pred shape: (2100000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 838us/step\n",
      "Pred shape: (2130000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 26s 876us/step\n",
      "Pred shape: (2160000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 832us/step\n",
      "Pred shape: (2190000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 26s 868us/step\n",
      "Pred shape: (2220000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 26s 854us/step\n",
      "Pred shape: (2250000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 26s 855us/step\n",
      "Pred shape: (2280000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 26s 859us/step\n",
      "Pred shape: (2310000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 26s 851us/step\n",
      "Pred shape: (2340000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 25s 832us/step\n",
      "Pred shape: (2370000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 31s 1ms/step\n",
      "Pred shape: (2400000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 26s 850us/step\n",
      "Pred shape: (2430000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 26s 851us/step\n",
      "Pred shape: (2460000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26554/26554 [==============================] - 24s 888us/step\n",
      "Pred shape: (2486554, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2486554\n",
      "Map3: 0.896\n"
     ]
    }
   ],
   "source": [
    "# run the validation\n",
    "import gc\n",
    "#gpu_model.load_weights('xception_model.h5') # best run - otherwise choose xception_model_last.h5\n",
    "#gpu_model.load_weights('xception_model_last.h5')\n",
    "valid_batch_size = 30000\n",
    "valid_data = pd.read_csv(os.path.join('./input/train_simplified_time_split_20/train_k19.csv.gz'))\n",
    "\n",
    "num_batch = np.ceil(len(valid_data)/valid_batch_size) # can override to reduce the number of validation\n",
    "counter = 0\n",
    "nrows = 0\n",
    "pred_valid_array = []\n",
    "\n",
    "while True:\n",
    "    batch_files = valid_data[valid_batch_size*counter:valid_batch_size*(counter+1)]\n",
    "    \n",
    "    x_valid = df_to_image_array_xd(batch_files, size)\n",
    "    p_valid = gpu_model.predict(x_valid, batch_size=1024, verbose=1)\n",
    "    \n",
    "    if counter == 0:\n",
    "        pred_valid_array = p_valid\n",
    "    else:\n",
    "        pred_valid_array = np.concatenate((pred_valid_array, p_valid), axis = 0)\n",
    "    print('Pred shape: {}'.format(pred_valid_array.shape))\n",
    "    \n",
    "    x_valid = []\n",
    "    gc.collect()\n",
    "    \n",
    "    counter += 1\n",
    "    nrows += len(batch_files)\n",
    "    if counter >= num_batch:\n",
    "            break\n",
    "\n",
    "print(nrows)\n",
    "map3 = mapk(valid_data[['y']].values, preds2catids(pred_valid_array).values)\n",
    "print('Map3: {:.3f}'.format(map3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom/anaconda2/envs/python36/lib/python3.6/site-packages/ipykernel_launcher.py:201: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/tom/anaconda2/envs/python36/lib/python3.6/site-packages/ipykernel_launcher.py:210: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 10s 1ms/step\n",
      "Pred shape: (10000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 11s 1ms/step\n",
      "Pred shape: (20000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 10s 1ms/step\n",
      "Pred shape: (30000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 10s 1ms/step\n",
      "Pred shape: (40000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 9s 936us/step\n",
      "Pred shape: (50000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 10s 1ms/step\n",
      "Pred shape: (60000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 11s 1ms/step\n",
      "Pred shape: (70000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 10s 1ms/step\n",
      "Pred shape: (80000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 10s 1ms/step\n",
      "Pred shape: (90000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 10s 1ms/step\n",
      "Pred shape: (100000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 10s 1ms/step\n",
      "Pred shape: (110000, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2199/2199 [==============================] - 2s 1ms/step\n",
      "Pred shape: (112199, 340)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112199\n"
     ]
    }
   ],
   "source": [
    "test_batch_size = 10000\n",
    "test = pd.read_csv(os.path.join('./input/test_simplified_time.csv'))\n",
    "\n",
    "num_batch = np.ceil(len(test)/test_batch_size)\n",
    "counter = 0\n",
    "nrows = 0\n",
    "pred_array = []\n",
    "\n",
    "while True:\n",
    "    batch_files = test[test_batch_size*counter:test_batch_size*(counter+1)]\n",
    "    \n",
    "    x_test = df_to_image_array_xd(batch_files, size)\n",
    "    p_test = gpu_model.predict(x_test, batch_size=256, verbose=1)\n",
    "    \n",
    "    if counter == 0:\n",
    "        pred_array = p_test\n",
    "    else:\n",
    "        pred_array = np.concatenate((pred_array, p_test), axis = 0)\n",
    "    print('Pred shape: {}'.format(pred_array.shape))\n",
    "    \n",
    "    x_valid = []\n",
    "    gc.collect()\n",
    "    \n",
    "    counter += 1\n",
    "    nrows += len(batch_files)\n",
    "    if counter >= num_batch:\n",
    "            break\n",
    "\n",
    "print(nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>234</td>\n",
       "      <td>281</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144</td>\n",
       "      <td>36</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>305</td>\n",
       "      <td>62</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>187</td>\n",
       "      <td>111</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>113</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a    b    c\n",
       "0  234  281  285\n",
       "1  144   36  226\n",
       "2  305   62  110\n",
       "3  187  111  304\n",
       "4   56  113  112"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(112199, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>radio</td>\n",
       "      <td>stereo</td>\n",
       "      <td>stove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hockey_puck</td>\n",
       "      <td>bottlecap</td>\n",
       "      <td>pool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The_Great_Wall_of_China</td>\n",
       "      <td>castle</td>\n",
       "      <td>fence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mountain</td>\n",
       "      <td>finger</td>\n",
       "      <td>The_Eiffel_Tower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>campfire</td>\n",
       "      <td>fireplace</td>\n",
       "      <td>fire_hydrant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         a          b                 c\n",
       "0                    radio     stereo             stove\n",
       "1              hockey_puck  bottlecap              pool\n",
       "2  The_Great_Wall_of_China     castle             fence\n",
       "3                 mountain     finger  The_Eiffel_Tower\n",
       "4                 campfire  fireplace      fire_hydrant"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(112199, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standard code from kernel to convert to submission file\n",
    "top3 = preds2catids(pred_array)\n",
    "top3.head()\n",
    "top3.shape\n",
    "\n",
    "def list_all_categories():\n",
    "    files = os.listdir(os.path.join(INPUT_DIR, 'train_simplified'))\n",
    "    return sorted([f2cat(f) for f in files], key=str.lower)\n",
    "\n",
    "cats = list_all_categories()\n",
    "id2cat = {k: cat.replace(' ', '_') for k, cat in enumerate(cats)}\n",
    "top3cats = top3.replace(id2cat)\n",
    "top3cats.head()\n",
    "top3cats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_id</th>\n",
       "      <th>countrycode</th>\n",
       "      <th>drawing</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9000003627287624</td>\n",
       "      <td>DE</td>\n",
       "      <td>[[[17, 18, 20, 25, 137, 174, 242, 249, 251, 25...</td>\n",
       "      <td>radio 0.8601467 stereo 0.13984916 stove 2.2499...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9000010688666847</td>\n",
       "      <td>UA</td>\n",
       "      <td>[[[174, 145, 106, 38, 11, 4, 4, 15, 29, 78, 16...</td>\n",
       "      <td>hockey_puck 0.9357352 bottlecap 0.043401606 po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9000023642890129</td>\n",
       "      <td>BG</td>\n",
       "      <td>[[[0, 12, 14, 17, 16, 24, 55, 57, 60, 79, 82, ...</td>\n",
       "      <td>The_Great_Wall_of_China 0.933876 castle 0.0563...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9000038588854897</td>\n",
       "      <td>US</td>\n",
       "      <td>[[[0, 9, 23, 40, 54, 60, 81, 105, 123, 167, 20...</td>\n",
       "      <td>mountain 0.9999802 finger 5.4075167e-06 The_Ei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9000052667981386</td>\n",
       "      <td>AR</td>\n",
       "      <td>[[[87, 82, 71, 63, 66, 92, 96, 95], [220, 218,...</td>\n",
       "      <td>campfire 0.56525826 fireplace 0.4194067 fire_h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             key_id countrycode  \\\n",
       "0  9000003627287624          DE   \n",
       "1  9000010688666847          UA   \n",
       "2  9000023642890129          BG   \n",
       "3  9000038588854897          US   \n",
       "4  9000052667981386          AR   \n",
       "\n",
       "                                             drawing  \\\n",
       "0  [[[17, 18, 20, 25, 137, 174, 242, 249, 251, 25...   \n",
       "1  [[[174, 145, 106, 38, 11, 4, 4, 15, 29, 78, 16...   \n",
       "2  [[[0, 12, 14, 17, 16, 24, 55, 57, 60, 79, 82, ...   \n",
       "3  [[[0, 9, 23, 40, 54, 60, 81, 105, 123, 167, 20...   \n",
       "4  [[[87, 82, 71, 63, 66, 92, 96, 95], [220, 218,...   \n",
       "\n",
       "                                                word  \n",
       "0  radio 0.8601467 stereo 0.13984916 stove 2.2499...  \n",
       "1  hockey_puck 0.9357352 bottlecap 0.043401606 po...  \n",
       "2  The_Great_Wall_of_China 0.933876 castle 0.0563...  \n",
       "3  mountain 0.9999802 finger 5.4075167e-06 The_Ei...  \n",
       "4  campfire 0.56525826 fireplace 0.4194067 fire_h...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### This section is for ensemble output only\n",
    "def preds2catids_pr(predictions, k=5):\n",
    "    topk = pd.DataFrame(np.argsort(-predictions, axis=1)[:, :k], columns=[chr(ord('a')+x) for x in range(k)])\n",
    "    \n",
    "    cats = list_all_categories()\n",
    "    id2cat = {k: cat.replace(' ', '_') for k, cat in enumerate(cats)}\n",
    "    topcats = topk.replace(id2cat)\n",
    "    \n",
    "    p_pr = pd.DataFrame(-np.sort(-predictions, axis=1)[:, :k])\n",
    "    p_all = pd.concat([topcats, p_pr], axis=1)\n",
    "    \n",
    "    # construct the word\n",
    "    p_all['word'] = \"\"\n",
    "    \n",
    "    for l in range(k):\n",
    "        p_all['word'] += (p_all[chr(ord('a')+l)] + \" \" + p_all[l].astype(str) + \" \")\n",
    "    \n",
    "    # reuse the test CSV for ids\n",
    "    test_df = pd.read_csv(os.path.join('./input/test_simplified.csv'))\n",
    "    test_df['word'] = p_all['word']\n",
    "    \n",
    "    return test_df \n",
    "\n",
    "x = preds2catids_pr(pred_array)\n",
    "x.head()\n",
    "\n",
    "# generate the top 5 pr CSV\n",
    "x[['key_id', 'word']].to_csv('xception128_rnn_top5_last.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_id</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9000003627287624</td>\n",
       "      <td>radio stereo stove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9000010688666847</td>\n",
       "      <td>hockey_puck bottlecap pool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9000023642890129</td>\n",
       "      <td>The_Great_Wall_of_China castle fence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9000038588854897</td>\n",
       "      <td>mountain finger The_Eiffel_Tower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9000052667981386</td>\n",
       "      <td>campfire fireplace fire_hydrant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             key_id                                  word\n",
       "0  9000003627287624                    radio stereo stove\n",
       "1  9000010688666847            hockey_puck bottlecap pool\n",
       "2  9000023642890129  The_Great_Wall_of_China castle fence\n",
       "3  9000038588854897      mountain finger The_Eiffel_Tower\n",
       "4  9000052667981386       campfire fireplace fire_hydrant"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(112199, 2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['word'] = top3cats['a'] + ' ' + top3cats['b'] + ' ' + top3cats['c']\n",
    "submission = test[['key_id', 'word']]\n",
    "submission.to_csv('xception128_rnn_map3_{}_v1.csv'.format(int(map3 * 10**4)), index=False)\n",
    "submission.head()\n",
    "submission.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xception 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-d0e4ddbb1381>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m340\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mgpu_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_gpu_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mgpu_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'xception_model256_cur.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python36/lib/python3.6/site-packages/keras/utils/training_utils.py\u001b[0m in \u001b[0;36mmulti_gpu_model\u001b[0;34m(model, gpus)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;31m# Apply model on slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0;31m# (creating a model replica on the target device).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python36/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python36/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_tensor_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0moutput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_internal_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python36/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mrun_internal_graph\u001b[0;34m(self, inputs, masks)\u001b[0m\n\u001b[1;32m    722\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0;34m'mask'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m                                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputed_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m                             \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m                             output_masks = layer.compute_mask(computed_tensor,\n\u001b[1;32m    726\u001b[0m                                                               computed_mask)\n",
      "\u001b[0;32m~/anaconda2/envs/python36/lib/python3.6/site-packages/keras/layers/normalization.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    193\u001b[0m         self.add_update([K.moving_average_update(self.moving_mean,\n\u001b[1;32m    194\u001b[0m                                                  \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m                                                  self.momentum),\n\u001b[0m\u001b[1;32m    196\u001b[0m                          K.moving_average_update(self.moving_variance,\n\u001b[1;32m    197\u001b[0m                                                  \u001b[0mvariance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mmoving_average_update\u001b[0;34m(x, value, momentum)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \"\"\"\n\u001b[1;32m   1011\u001b[0m     return moving_averages.assign_moving_average(\n\u001b[0;32m-> 1012\u001b[0;31m         x, value, momentum, zero_debias=True)\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python36/lib/python3.6/site-packages/tensorflow/python/training/moving_averages.py\u001b[0m in \u001b[0;36massign_moving_average\u001b[0;34m(variable, value, decay, zero_debias, name)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mdecay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mzero_debias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mupdate_delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_zero_debias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mupdate_delta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python36/lib/python3.6/site-packages/tensorflow/python/training/moving_averages.py\u001b[0m in \u001b[0;36m_zero_debias\u001b[0;34m(unbiased_var, value, decay)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"_%d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m       biased_var = variable_scope.get_variable(\n\u001b[0;32m--> 211\u001b[0;31m           \u001b[0m_maybe_get_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"biased\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbiased_initializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m           trainable=False)\n\u001b[1;32m    213\u001b[0m       local_step = variable_scope.get_variable(\n",
      "\u001b[0;32m~/anaconda2/envs/python36/lib/python3.6/site-packages/tensorflow/python/training/moving_averages.py\u001b[0m in \u001b[0;36m_maybe_get_unique\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    201\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         vs_vars = [x.op.name for x in\n\u001b[0;32m--> 203\u001b[0;31m                    variable_scope.get_variable_scope().global_variables()]\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0mfull_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariable_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfull_name\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvs_vars\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python36/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mglobal_variables\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1139\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mglobal_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m     \u001b[0;34m\"\"\"Get this scope's global variables.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGLOBAL_VARIABLES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mlocal_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python36/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_collection\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[0;34m\"\"\"Get this scope's variables.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m     \u001b[0mscope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_collection\u001b[0;34m(key, scope)\u001b[0m\n\u001b[1;32m   5672\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mend_compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5673\u001b[0m   \"\"\"\n\u001b[0;32m-> 5674\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_collection\u001b[0;34m(self, name, scope)\u001b[0m\n\u001b[1;32m   3692\u001b[0m         \u001b[0mregex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3693\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollection\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3694\u001b[0;31m           \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"name\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3695\u001b[0m             \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3696\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/python36/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36mname\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    986\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m     \u001b[0;34m\"\"\"The name of this variable.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 988\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "base_model = Xception(input_shape = (256, 256, 3), include_top = False, weights = 'imagenet')\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dense(340, activation = 'softmax')(x)\n",
    "model = Model(inputs = base_model.input, outputs = x)\n",
    "gpu_model = multi_gpu_model(model, 2)\n",
    "print(gpu_model.summary())\n",
    "gpu_model.load_weights('xception_model256_cur.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Xception 256\n",
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "EPOCHS = 100\n",
    "TOTAL_TRAIN = 2250000\n",
    "BATCH_SIZE = 32 * 2\n",
    "STEPS = TOTAL_TRAIN // BATCH_SIZE\n",
    "\n",
    "train_datagen = image_generator_xd(size=size, batchsize=BATCH_SIZE, ks=range(NCSVS - 1))\n",
    "valid_datagen = image_generator_xd(size=size, batchsize=BATCH_SIZE, ks=NCSVS - 1)\n",
    "\n",
    "def step_decay_exp(epoch):\n",
    "    initial_lrate = 0.00075\n",
    "    drop = 0.5 # drop by how much? 0.5 = half each time\n",
    "    epochs_drop = 7.0 # drop how many x epochs\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return max(1e-6, lrate)\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint('xception_model256.h5', monitor = 'val_top_3_accuracy', mode = 'max', save_best_only = True, verbose = 1),\n",
    "    ModelCheckpoint('xception_model256_cur.h5', monitor = 'val_top_3_accuracy', mode = 'max', save_best_only = False, verbose = 0),\n",
    "    ReduceLROnPlateau(monitor='val_top_3_accuracy', factor=0.66, patience=3,\n",
    "                      min_lr = 0.000001, \n",
    "#                       min_delta=0.005, \n",
    "                      mode='max', \n",
    "                      cooldown=3, verbose=1),\n",
    "#     LearningRateScheduler(step_decay_exp),\n",
    "    CSVLogger('xception_log256.csv', append=True, separator=';')\n",
    "]\n",
    "\n",
    "# sgdOptimiser = SGD(lr = 0.001,  momentum=0.9, decay = 0.0001,  nesterov=True)\n",
    "\n",
    "gpu_model.compile(optimizer=Adam(lr=0.00015), loss='categorical_crossentropy',\n",
    "              metrics=[categorical_crossentropy, categorical_accuracy, top_3_accuracy])\n",
    "\n",
    "gpu_model.load_weights('xception_model256_cur.h5')\n",
    "\n",
    "gpu_model.fit_generator(\n",
    "    train_datagen, steps_per_epoch=STEPS, epochs=EPOCHS, verbose=1,\n",
    "    validation_data = valid_datagen, validation_steps = STEPS // 8,\n",
    "    callbacks = callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_size = 5000\n",
    "test = pd.read_csv(os.path.join('test_simplified.csv'))\n",
    "\n",
    "num_batch = np.ceil(len(test)/test_batch_size)\n",
    "counter = 0\n",
    "nrows = 0\n",
    "pred_array = []\n",
    "\n",
    "while True:\n",
    "    batch_files = test[test_batch_size*counter:test_batch_size*(counter+1)]\n",
    "    \n",
    "    x_test = df_to_image_array_xd(batch_files, 256)\n",
    "    p_test = gpu_model.predict(x_test, batch_size=256, verbose=1)\n",
    "    \n",
    "    if counter == 0:\n",
    "        pred_array = p_test\n",
    "    else:\n",
    "        pred_array = np.concatenate((pred_array, p_test), axis = 0)\n",
    "    print('Pred shape: {}'.format(pred_array.shape))\n",
    "    \n",
    "    x_valid = []\n",
    "    gc.collect()\n",
    "    \n",
    "    counter += 1\n",
    "    nrows += len(batch_files)\n",
    "    if counter >= num_batch:\n",
    "            break\n",
    "\n",
    "print(nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = preds2catids_pr(pred_array)\n",
    "x.head()\n",
    "\n",
    "# generate the top 5 pr CSV\n",
    "x[['key_id', 'word']].to_csv('xception256_top5_last.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
